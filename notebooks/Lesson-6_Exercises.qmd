---
title: "Tema 6: PEC"
format:
  html:
    code-copy:       true
    code-tools:      true
    df-print:        paged
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
bibliography:        ../www/abd.bib
csl:                 ../www/apa-old-doi-prefix.csl
callout-appearance: minimal
---

# Introducción

En este tema hemos estudiado el concepto de **distribución predictiva** y cómo se puede estimar de manera sencilla mediante el método de Monte Carlo.

También hemos visto:

-   Cómo realizar comprobaciones predictivas con la **distribución predictiva posterior** (lo que llamamos **comprobaciones predictivas posteriores**, posterior predictive checks, o PPCs).

-   Cómo calcular **valores-p predictivos posteriores** para hacer inferencias y evaluar la discrepancia entre los datos observados y la distribución predictiva.

-   Cómo usar la **distribución predictiva previa** para evaluar la adecuación de la distribución previa a los datos observados.

En estos ejercicios, vamos a poner en práctica estos conceptos con algunos modelos ya conocidos y estudiados.
En este caso, vamos a utilizar los modelos beta-binomial y gamma-Poisson ya vistos en los temas anteriores.

Fíjate que @ross2022 asume distribuciones discreta (y no siempre uniformes) para el parámetro de probabilidad **en los ejemplos 7.1 a 7.4**.
Es decir, aunque la distribución de la variable observada sea binomial, **no se trata de modelos beta-binomiales**.

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)
library(scales)


# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto <- PALETA[1]      # Color por defecto
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica

# Redondea los números reales "inline":
options(digits = 3L)                
options(knitr.digits.signif = FALSE)

# Inicializa la semilla aleatoria:
set.seed(20250327)
```

Inicializamos el entorno como es habitual.
Dado que, además, vamos a utilizar el método de Monte Carlo, **hemos inicializado la semilla aleatoria**, para asegurar la **reproducibilidad de los resultados**.

# Ejercicio 1: Modelo beta-binomial de la "tasa de aceptación"

## Distribución predictiva previa

Vamos a empezar utilizando el ejemplo ya familiar que introdujimos en el Tema 3.

Recuerda que se trata de un modelo beta-binomial en el que el parámetro $\theta$ representa la "tasa de aceptación" de los/as usuari/as que han probado un app, a los que les pregunta si la descargarían en su móvil.

Los datos que se han obtenido en las dos muestras de la investigación son:

```{r beta-binomial-muestra}
aceptacion_muestra_1 <- tibble(
  id_participante   = 1:22,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si"
  )
)

# Tamaño de la muestra (necesario para enunciados más adelante)
n_muestra_1 <- aceptacion_muestra_1 |> count() |> pull()

aceptacion_muestra_2 <- tibble(
  id_participante   = 1:113,
  resp_descarga_app = c(
    "Si", "Si", "No", "No", "Si", "Si", "Si", "Si", "No", "Si", "Si",
    "Si", "Si", "Si", "Si", "Si", "No", "Si", "No", "Si", "Si", "Si", 
    "No", "Si", "Si", "Si", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "Si", "Si", "Si", "No", "Si", "No", "No", "Si", "No", "Si", "Si", 
    "No", "No", "No", "Si", "No", "No", "Si", "Si", "No", "No", "Si", 
    "No", "Si", "No", "No", "No", "Si", "Si", "No", "Si", "Si", "No", 
    "Si", "Si", "No", "Si", "Si", "No", "Si", "No", "Si", "No", "Si", 
    "No", "No", "No", "Si", "Si", "No", "No", "Si", "Si", "No", "No", 
    "No", "Si", "Si", "No", "Si", "Si", "No", "Si", "Si", "Si", "Si", 
    "No", "Si", "No", "No", "No", "No", "No", "Si", "No", "No", "Si", 
    "Si", "Si", "Si"
  )
)
```

Como en temas anteriores, vamos a utilizar una distribución no informativa para representar nuestra creencia a priori sobre la tasa de aceptación.

### Pregunta 1

-   Aproxima la distribución previa de $\theta$ por el método de Monte Carlo de manera que el valor esperado tenga una precisión de 0.01 con el 99% de probabilidad. Comprueba que la media y varianza se aproximan a los valores teóricos y representa la distribución resultante.

::: {#respuesta-1 .callout-note}
```{r}
# Parámetros de la distribución no informativa Beta(1,1)
alpha <- 1
beta <- 1
var_teorica <- (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1)) #Da 1/12

# Cálculo del tamaño muestral para que el MCSE ≤ 0.01 e IC=99% (que debe ser bilateral)
mcse_requerido <- 0.01 #Al ser menor o igual, no hace falta calcularlo con redondeo de 0,05 como en el Tema5.
z_99 <- qnorm(0.995) #Por ser bilateral
n_mcse <- ceiling((z_99^2 * var_teorica) / (mcse_requerido^2)) #Será el número de simulaciones a usar.

# Simulación para la predicción a priorir
theta_sim <- rbeta(n_mcse, alpha, beta) #Genera el número de thetas que se calculó antes en la distribución a priori.
media_sim <- mean(theta_sim) #Media de las thetas simuladas
var_sim   <- var(theta_sim) #Varianza de las thetas simuladas
mcse_sim  <- sd(theta_sim) / sqrt(n_mcse) #MCSE, solo por comprobar que efectivamente es el esperado.

# Visualización previa simulada de theta

ggplot(data.frame(theta = theta_sim), aes(x = theta)) +
  geom_histogram(aes(y = ..density..), bins = 50, fill = color_defecto, color = "black") +
  stat_function(fun = dbeta, args = list(shape1 = alpha, shape2 = beta),
                color = "red", linetype = "dashed", linewidth = 1) + #Nota: este argumento es para funciones continuas, no discretas
  labs(
    title = "Distribución previa simulada de θ (Beta(1,1))",
    subtitle = paste0("n = ", n_mcse, 
                      " | Media = ", round(media_sim, 3), #He tenido que añadir el round manualmente.
                      " | Var = ", round(var_sim, 3),
                      " | MCSE (99%) = ", round(2*mcse_sim, 2)),
    x = expression(theta),
    y = "Densidad"
  ) +
  coord_cartesian(xlim = c(0, 1))  # Limita el eje X entre 0 y 1, lo que abarca el rango uniforme de Beta (1,1).
```

#Se observa que no hay patrones claros en la distribución.
Como dato interesante, si se aumenta el número de bins a valores muy altos o muy bajos, la distribución se vuelve perfectamente uniforme.

```{r}
#Analíticamente
comparacion <- tibble(
  parametro = c("Media", "Varianza"),
  teorico   = c(
    alpha / (alpha + beta),
    (alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))
  ),
  simulado  = c(media_sim, var_sim),
  diferencia = c(
    abs(media_sim - (alpha / (alpha + beta))),
    abs(var_sim - ((alpha * beta) / ((alpha + beta)^2 * (alpha + beta + 1))))
  )
)
comparacion

```

#Las diferencias entre el resultado empírico y el simulado son mínimas.
:::

### Pregunta 2

-   A partir de la distribución previa simulada de $\theta$, simula los resultados de pruebas binomiales para la primera muestra del estudio. (Ten en cuenta que debe tener el tamaño muestral correspondiente). Representa la distribución predictiva previa resultante e interprétala.

::: {#respuesta-2 .callout-note}
```{r}
# Definir el tamaño de la muestra (ya dado)
n_muestra_1

# Simulación de los resultados binomiales para cada valor de theta simulada
resultados_binomiales <- rbinom(length(theta_sim), size = n_muestra_1, prob = theta_sim)

# Histograma de la distribución predictiva previa
ggplot(data.frame(resultados = resultados_binomiales), aes(x = resultados)) +
  geom_histogram(aes(y = ..density..), bins = 23, fill = color_defecto, color = "black") +
  labs(
    title = "Distribución Predictiva Previa de Aceptación (Primera Muestra)",
    subtitle = paste0("n = ", n_muestra_1, 
                      " | Media = ", round(mean(resultados_binomiales), 3), 
                      " | Var = ", round(var(resultados_binomiales), 3)),
    x = "Número de Aceptaciones",
    y = "Densidad"
  ) +
  coord_cartesian(xlim = c(0, n_muestra_1))  # Limita el eje entre 0 y n=22
```

#De nuevo, ningún patrón claro.
:::

### Pregunta 3

-   Utilizando la distribución predictiva previa de la pregunta anterior, calcula en qué centil se encuentra la primera muestra empírica del estudio de aceptación. ¿Cuál es la probabilidad de obtener un valor igual o mayor que este? ¿Y un valor igual o menor?

::: {#respuesta-3 .callout-note}
```{r}
# Recuento de "sí" (éxitos) en la primera muestra
n_aceptaciones_muestra_1 <- sum(aceptacion_muestra_1$resp_descarga_app == "Si")

# Calcular el centil en el que se encuentra 17
centil_muestra1 <- mean(resultados_binomiales < n_aceptaciones_muestra_1) * 100 

#El centil da un valor decimal porque el cálculo es meramente matemático, por lo que se puede redondear de varias maneras. Aquí, con un redondeo simple, aunque también se podría hacer a la parte entera con floor().
centil_muestra_1<-round(centil_muestra1,0)
#centil_muestra_1<-floor(centil_muestra1)


# Probabilidad de obtener un valor mayor o igual al observado en simulaciones de MC
prob_mayor_igual <- mean(resultados_binomiales >= n_aceptaciones_muestra_1)

# Probabilidad de obtener un valor menor o igual al observado en simulaciones de MC
prob_menor_igual <- mean(resultados_binomiales <= n_aceptaciones_muestra_1)

# Resultados
resultados_tibble <- tibble(
  Centil = centil_muestra_1,
  Probabilidad_Mayor_O_Igual = round(prob_mayor_igual, 3),
  Probabilidad_Menor_O_Igual = round(prob_menor_igual, 3)
)
resultados_tibble
```

#El centil indica que el 74% de los datos se encuentran por debajo del valor observado.
#Las probabilidades no suman exactamente 1 porque la desigualdad toma valores repetidos etre casos (es \>= y \<= en ambos casos, no \> en uno y \<= en otro, o viceversa).
:::

## Distribución predictiva posterior

### Pregunta 4

-   Utiliza el mismo nº de muestras de Monte Carlo de la distribución previa para aproximar la distribución posterior de $\theta$. (Utiliza la propiedad ya conocida de la conjugación para muestrear de la distribución posterior). Representa la distribución posterior obtenida.

::: {#respuesta-4 .callout-note}
```{r}
# Número de éxitos en la primera muestra (ya calculado) y fracasos (respuestas negativas)
n_aceptaciones_muestra_1
n_fracasos_muestra_1 <- n_muestra_1 - n_aceptaciones_muestra_1

# Actualización de los parámetros de la distribución Beta según la fórmula teórica
alpha_posterior <- alpha + n_aceptaciones_muestra_1
beta_posterior <- beta + n_fracasos_muestra_1

# Muestreo MC de la distribución Beta posterior. 
theta_posterior_sim <- rbeta(n_mcse, alpha_posterior, beta_posterior) #Mismo n_mcse que se calculó antes.

# Visualizar la distribución posterior
ggplot(data.frame(theta = theta_posterior_sim), aes(x = theta)) +
  geom_histogram(aes(y = ..density..), bins = 50, fill = color_defecto, color = "black") +
  stat_function(fun = dbeta, args = list(shape1 = alpha_posterior, shape2 = beta_posterior),
                color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "Distribución Posterior Simulada de θ (Beta Posterior)",
    subtitle = paste0("n = ", n_muestra_1, 
                      " | Media = ", round(mean(theta_posterior_sim), 3), 
                      " | Var = ", round(var(theta_posterior_sim), 3)),
    x = expression(theta),
    y = "Densidad"
  ) +
  coord_cartesian(xlim = c(0, 1))  # Limitar el eje x entre 0 y 1, rango posible de theta.
```
:::

### Pregunta 5

-   A partir de la distribución posterior simulada de $\theta$, simula los resultados de pruebas binomiales para la primera muestra del estudio y represéntala.

::: {#respuesta-5 .callout-note}
```{r}

# Simulación de los resultados binomiales a partir de la posterior
resultados_binomiales_posterior <- rbinom(length(theta_posterior_sim), size = n_muestra_1,prob = theta_posterior_sim)

# Visualización de los resultados binomiales simulados
ggplot(data.frame(resultados = resultados_binomiales_posterior), aes(x = resultados)) +
  geom_histogram(aes(y = ..density..), bins = 10, fill = color_defecto, color = "black") +
  geom_vline(aes(xintercept = mean(resultados_binomiales_posterior)),
             color = "blue", linetype = "dashed", linewidth = 1) +  # Línea media
  labs(
    title = "Resultados de Pruebas Binomiales Simuladas a partir de la Distribución Posterior de θ",
    subtitle = paste0("n sim = ", length(resultados_binomiales_posterior), 
                      " | Media posterior = ", round(mean(resultados_binomiales_posterior), 3),
                      " | Var posterior = ", round(var(resultados_binomiales_posterior), 3)),
    x = "Número de respuestas afirmativas",
    y = "Densidad"
  ) +
  coord_cartesian(xlim = c(0, n_muestra_1))
```
:::

Lo que acabas de representar es la **distribución predictiva posterior** del modelo ajustado con la muestra 1 del estudio.

### Pregunta 6

-   Obten las distribuciones posterior y predictiva posterior con la muestra 2, **asumiendo desconocimiento total sobre la tasa de aceptación** (i.e., distribución no informativa).

::: {#respuesta-6 .callout-note}
```{r}
# Número de casos, éxitos y fracasos en la muestra 2
n_muestra_2 <- aceptacion_muestra_2 |> count() |> pull()
n_aceptaciones_muestra_2<-sum(aceptacion_muestra_2$resp_descarga_app == "Si")
n_fracasos_muestra_2 <- n_muestra_2 - n_aceptaciones_muestra_2

#Definir una nueva beta no informativa (aunque se podría usar la anterior, solo para no sobreescribir elementos)
alpha2<-1
beta2<-1

# Actualizar los parámetros de la Beta posterior
alpha_posterior2 <- alpha2 + n_aceptaciones_muestra_2
beta_posterior2 <- beta2 + n_fracasos_muestra_2

# Muestreo MC de la distribución Beta posterior. 
theta_posterior_sim2 <- rbeta(n_mcse, alpha_posterior2, beta_posterior2) #Mismo n para obtener resultados comparables en términos de error de simulación.

# Visualizar la distribución posterior
ggplot(data.frame(theta = theta_posterior_sim2), aes(x = theta)) +
  geom_histogram(aes(y = ..density..), bins = 50, fill = color_defecto, color = "black") +
  stat_function(fun = dbeta, args = list(shape1 = alpha_posterior2, shape2 = beta_posterior2),
                color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "Distribución Posterior Simulada de θ (Beta Posterior)",
    subtitle = paste0("n = ", n_muestra_2, 
                      " | Media = ", round(mean(theta_posterior_sim2), 3), 
                      " | Var = ", round(var(theta_posterior_sim2), 3)),
    x = expression(theta),
    y = "Densidad"
  ) +
  coord_cartesian(xlim = c(0, 1))  # Limitar el eje x entre 0 y 1, rango posible de theta
```

```{r}
# Simulación de los resultados binomiales a partir de la distribución posterior 2 de theta
resultados_binomiales_posterior2 <- rbinom(length(theta_posterior_sim2), size = n_muestra_2,prob = theta_posterior_sim2)

# Visualización de los resultados binomiales simulados
ggplot(data.frame(resultados = resultados_binomiales_posterior2), aes(x = resultados)) +
  geom_histogram(aes(y = ..density..), bins = 15, fill = color_defecto, color = "black") +
  geom_vline(aes(xintercept = mean(resultados_binomiales_posterior2)),
             color = "blue", linetype = "dashed", linewidth = 1) +  # Línea media de la posterior predictiva
  labs(
    title = "Resultados de Pruebas Binomiales Simuladas a partir de la Distribución Posterior Predictiva de θ",
    subtitle = paste0("n = ", length(resultados_binomiales_posterior2), 
                      " | Media = ", round(mean(resultados_binomiales_posterior2), 3),
                      " | Varianza = ", round(var(resultados_binomiales_posterior2), 3)),
    x = "Número de respuestas afirmativas",
    y = "Densidad"
  ) +
  coord_cartesian(xlim = c(0, n_muestra_2))
```
:::

## Comprobaciones predictivas posteriores

### Pregunta 7

-   Dada la distribución posterior tras el ajuste del modelo con la muestra 2, aproxima la distribución predictiva posterior para un tamaño muestral de `{r} n_muestra_1`. Represéntala junto con la distribución predictiva posterior resultante de ajustar el modelo con la muestra 1, y representa mediante una línea vertical el valor obtenido de la muestra empírica 1.

::: {#respuesta-7 .callout-note}
```{r}
# Simulación de la distribución predictiva posterior para la muestra 2 con n_muestra_1
resultados_binomiales_posterior_2_muestra_1 <- rbinom(length(theta_posterior_sim2), size = n_muestra_1,prob = theta_posterior_sim2)

# Visualización de ambas distribuciones predictivas y línea vertical para el valor de la muestra empírica 1
ggplot() +
  # Distribución predictiva posterior para la muestra 1 (usando theta_posterior_sim)
  geom_histogram(data = data.frame(resultados = resultados_binomiales_posterior, 
                                    grupo = rep("Muestra 1", length(resultados_binomiales_posterior))),
                 aes(x = resultados, y = ..density.., fill = grupo), 
                 bins = 15, color = "black", alpha = 0.6) +
  
  # Distribución predictiva posterior para la muestra 2 (usando theta_posterior_sim_2)
  geom_histogram(data = data.frame(resultados = resultados_binomiales_posterior_2_muestra_1, 
                                    grupo = rep("Muestra 2", length(resultados_binomiales_posterior_2_muestra_1))),
                 aes(x = resultados, y = ..density.., fill = grupo), 
                 bins = 15, color = "black", alpha = 0.6) +
  
  # Línea vertical para el valor de la muestra empírica 1 (número de éxitos en la muestra 1)
  geom_vline(xintercept = n_aceptaciones_muestra_1, color = PALETA[3], linetype = "dashed", linewidth = 1) +
  labs(
    title = "Distribuciones Predictivas Posteriores para las Muestras 1 y 2",
        subtitle = paste0("n muestral predictivo = ", n_muestra_1),
    x = "Número de respuestas afirmativas",
    y = "Densidad"
  ) +
  scale_fill_manual(values = c(color_defecto, PALETA[2])) +
  theme_minimal() + # He probado a quitarlo, pero se ve mucho más congestionado
  theme(
    legend.title = element_blank(),  
    legend.position = "top",         
    legend.text = element_text(size = 10) 
  ) +
  scale_x_continuous(breaks = seq(0, n_muestra_1, by = 1))  # by ajusta las marcas del eje x para mayor precisión
```
:::

### Pregunta 8

-   Calcula, en el modelo ajustado con la muestra 2, la probabilidad de obtener un valor mayor o igual / menor o igual que la primera muestra empírica. ¿Cómo se representan estas probabilidades en el gráfico anterior?

::: {#respuesta-8 .callout-note}
#El cálculo es bastante directo mediante las medias de las posteriores

```{r}
# Calcular las probabilidades de obtener un valor menor o igual y mayor o igual
prob_menor_igual_muestra_2 <- mean(resultados_binomiales_posterior_2_muestra_1 <= n_aceptaciones_muestra_1)
prob_mayor_igual_muestra_2 <- mean(resultados_binomiales_posterior_2_muestra_1 >= n_aceptaciones_muestra_1)

# Resultados
resultados9 <- tibble(
  "Probabilidad Menor o Igual" = round(prob_menor_igual_muestra_2, 3),
  "Probabilidad Mayor o Igual" = round(prob_mayor_igual_muestra_2, 3)
)
resultados9
```

#A nivel de interpretación, P(menor o igual) se representa como el área a la izquierda del valor observado de la primera muestra empírica (la línea vertical) en la distribución predictiva posterior de la muestra 2. Al ser alto, indica que la probabilidad de encontrar un valor menor o igual a X bajo el modelo es alta.

#La P (mayor o igual) es al revés, el área desde la línea a la derecha hasta el final de la distribución predictiva posterior de la muestra 2. Al ser bajo (aunque mayor que el valor crítico típco frecuentista 0,05), indica que la probabilidad de encontrar un valor mayor o igual a X bajo el modelo es baja.
:::

### Pregunta 9

-   Si te preguntasen por el *valor-*$p$ *predictivo posterior* de la hipótesis que "la muestra 1 esté extraída de la misma población que la muestra 2", ¿qué valor reportarías y cómo lo interpretarías?

::: {#respuesta-9 .callout-note}
#Reportaría el valor P (mayor o igual) ya que, en una analogía con el p-valor frecuentista (salvando las distancias), nos informaría de que el valor que hemos obtenido en la primera muestra es muy extremo por encima (ya que el valor es superior a la tendencia central de la 2) en comparación con lo esperado a partir de la distribución posterior de los datos de la segunda muestra; es decir, es muy improbable encontrarvalores iguales o mayores al empírico.

#En otra línea de interpretación, sugiere que el modelo 2 con n_muestra_1 no ajusta bien a los datos, ya que es muy improbable observar el valor empírico.
:::

### Pregunta 10

-   Prueba a hacerlo a la inversa; es decir, ajusta el modelo con la muestra 1, y después realiza la *comprobación predictiva posterior* de si la muestra 2 proviene de la misma población que la muestra 1. ¿Qué conclusión obtendrías?

::: {#respuesta-10 .callout-note}
```{r}
#Analíticamente, los valores P predictivos:

# Simulación de la distribución predictiva posterior para la muestra 1 con n_muestra_2
resultados_binomiales_posterior_1_muestra_2 <- rbinom(length(theta_posterior_sim), size = n_muestra_2,prob = theta_posterior_sim)

#El cálculo vuelve a ser bastante directo mediante las medias de las posteriores
prob_menor_igual_muestra_1 <- mean(resultados_binomiales_posterior_1_muestra_2 <= n_aceptaciones_muestra_2)
prob_mayor_igual_muestra_1 <- mean(resultados_binomiales_posterior_1_muestra_2 >= n_aceptaciones_muestra_2)

# Mostrar las probabilidades
resultados10<- tibble(
  "Probabilidad Menor o Igual" = round(prob_menor_igual_muestra_1, 3),
  "Probabilidad Mayor o Igual" = round(prob_mayor_igual_muestra_1, 3)
)
resultados10


```

#Los resultados son prácticamente idénticos en términos de información, solo que la cola interpretable ahora es la menor, que vuelve a mostrar lo improbable que es que el dato de la muestra 1 correspondan con los de la 2 de acuerdo a sus distribuciones a posteriori.

```{r}
# Visualmente

ggplot() +
  # Distribución predictiva posterior para la muestra 1 (usando theta_posterior_sim2)
  geom_histogram(data = data.frame(resultados = resultados_binomiales_posterior_1_muestra_2, 
                                   grupo = rep("Muestra 1", length(resultados_binomiales_posterior_1_muestra_2))),
                 aes(x = resultados, y = ..density.., fill = grupo), 
                 bins = 15, color = "black", alpha = 0.6) +
  
  # Distribución predictiva posterior para la muestra 2
  geom_histogram(data = data.frame(resultados = resultados_binomiales_posterior2, 
                                   grupo = rep("Muestra 2", length(resultados_binomiales_posterior2))),
                 aes(x = resultados, y = ..density.., fill = grupo), 
                 bins = 15, color = "black", alpha = 0.6) +
  
  # Línea vertical para el valor de la muestra empírica 1 (número de éxitos en la muestra 1)
  
  geom_vline(xintercept = n_aceptaciones_muestra_2, color = PALETA[3], linetype = "dashed", linewidth = 1) +
  labs(
    title = "Distribuciones Predictivas Posteriores para las Muestras 1 y 2",
    subtitle = paste0("n muestral predictivo = ", n_muestra_2),
    x = "Número de respuestas afirmativas",
    y = "Densidad"
  ) +
  scale_fill_manual(values = c(color_defecto, PALETA[2])) +
  theme_minimal() + # He probado a quitarlo, pero se ve mucho más congestionado
  theme(
    legend.title = element_blank(), #Este comando hace que no aparezca "grupo" (el título de la leyenda)
    legend.position = "top",         
    legend.text = element_text(size = 10) 
  ) +
  scale_x_continuous(breaks = seq(0, n_muestra_2, by = 5))  # By ajusta las marcas del eje x para mayor precisión

```
:::

:::

# Ejercicio 2: Modelo gamma-Poisson de la "tasa de fertilidad"

El ejercicio anterior se basa en la distribución beta-binomial, que permite simplificar la distribución predictiva posterior al necesitar generar únicamente un valor observado (nº de usuarios que "aceptan" la aplicación) para cada muestra.
Sin embargo, es habitual encontrar distribuciones predictivas posteriores más complejas o derivadas, como hemos visto en la lectura.
En el siguiente ejemplo veremos cómo simular muestras de una distribución predictiva posterior utilizando el modelo "gamma-Poisson".

## Distribución predictiva posterior

En [la lectura del Tema 5](https://agora.uned.es/mod/resource/view.php?id=512338) (@hoff2009) y los ejercicios vimos el ejemplo de las tasas de fertilidad de mujeres de 40 años con y sin título universitario, con datos de la Encuesta Social General de los EEUU durante la década de los 1990 [los detalles están en @hoff2009, capítulo 3].

A continuación tienes los datos que aparecen en la lectura, los estadísticos resumen para cada grupo, y una representación gráfica:

```{r datos-fertilidad-gss-1990}
fertilidad_gss_1990 <- tibble(
  titulo_uni = c("sin" |> rep(7),                 "con" |> rep(5)),
  n_hijos    = c(0:6,                             0:4),
  frecuencia = c(20L, 19L, 38L, 20L, 10L, 2L, 2L, 11L, 11L, 13L, 7L, 2L)
) |>
  # Rellena los niveles para hacer ambas muestras más "comparables":
  complete(titulo_uni, n_hijos, fill = list(frecuencia = 0))

fert_estadisticos <- fertilidad_gss_1990 |>
  group_by(titulo_uni) |>
  summarize(y = sum(n_hijos * frecuencia), n = sum(frecuencia))

fert_estadisticos # y = nº hijos en cada grupo, n = nº mujeres en cada grupo

fertilidad_gss_1990 |>
  ggplot(aes(n_hijos, frecuencia, fill = titulo_uni)) +
  geom_col(position = "dodge") +
  labs(fill = "Título universitario", x  = "Nº hijos", y = "Frecuencia")
```

La distribución posterior de la tasa de fertilidad $\lambda$ en el modelo gamma-Poisson puede obtenerse mediante conjugación de la distribución previa $\lambda \sim Gamma(a, b)$, y viene dada por $\lambda \sim Gamma(a + \sum y_i, b + n)$, siendo $\sum y_i$ el nº total de ocurrencias observadas en una muestra (en nuestro caso, nº total de hijos en la muestra / cada grupo) y $n$ el nº total de casos (nº de mujeres la muestra / en cada grupo).

Como vimos en los ejercicios del tema 5, las distribuciones posteriores para cada grupo, asumiendo una distribución previa $\lambda \sim Gamma(2, 1)$, vienen dadas por:

```{r fertilidad-ajuste}
A_PRE <- 2L
B_PRE <- 1L

params_fertilidad <- fert_estadisticos |> mutate(
  a_post = A_PRE + y,
  b_post = B_PRE + n
)

params_fertiliad_sin <- params_fertilidad |>
  filter(titulo_uni == "sin") 
a_post_sin <- params_fertiliad_sin |> pull(a_post)
b_post_sin <- params_fertiliad_sin |> pull(b_post)

params_fertiliad_con <- params_fertilidad |>
  filter(titulo_uni == "con") 
a_post_con <- params_fertiliad_con |> pull(a_post)
b_post_con <- params_fertiliad_con |> pull(b_post)
```

$$
  (\lambda | y_{sin}) \sim Gamma(`{r} a_post_sin`, `{r} b_post_sin`)
$$

$$
  (\lambda | y_{con}) \sim Gamma(`{r} a_post_con`, `{r} b_post_con`)
$$

### Pregunta 11

-   Utilizando 10^6^ muestras simuladas, aproxima las dos distribuciones posteriores y represéntalas.

*(Nota: Para representar una densidad directamente con `ggplot()` a partir de las muestras de simuladas, consulta la ayuda de `geom_density()`)*

::: {#respuesta-11 .callout-note}
```{r}
# Simulaciones: 10^6 muestras de cada distribución posterior
n_sim <- 1e6
lambda_sin <- rgamma(n_sim, shape = a_post_sin, rate = b_post_sin)
lambda_con <- rgamma(n_sim, shape = a_post_con, rate = b_post_con)

#  Crear data frame unificado para ambas muestras
df_lambda <- bind_rows(
  tibble(lambda = lambda_sin, grupo = "Sin título universitario"),
  tibble(lambda = lambda_con, grupo = "Con título universitario")
)

# Graficar las distribuciones posteriores
ggplot(df_lambda, aes(x = lambda, fill = grupo)) +
  geom_density(alpha = 0.6, color = NA) +
  labs(
    title = "Distribuciones posteriores de λ según nivel educativo",
    subtitle = paste0(
      "Media λ con título: ", round(mean(lambda_con), 2),
      " | Media λ sin título: ", round(mean(lambda_sin), 2)
    ),
    x = expression(lambda ~ "(tasa de hijos por mujer)"),
    y = "Densidad"
  ) +
  scale_fill_manual(values = c(PALETA[1], PALETA[2])) +
   theme(
    legend.position = "top",
    legend.title = element_blank(), #Este comando hace que no aparezca "grupo" (el título de la leyenda)
    legend.text = element_text(size = 10),
    plot.title = element_text(face = "bold", hjust = 0.5),  # hjust centra el texto sobre el gráfico
    plot.subtitle = element_text(hjust = 0.5) 
  )

```
:::

### Pregunta 12

-   A partir de las distribuciones posteriores de $\lambda$, aproxima las distribuciones predictivas posteriores simulando datos de la distribución de Poisson (consulta la ayuda de `rpois()` si lo necesitas). Representa las distribuciones predictivas posteriores de ambos grupos.

::: {#respuesta-12 .callout-note}
```{r}
# Para cada valor de lambda en la posterior, simular un valor de hijos
hijos_sin <- rpois(length(lambda_sin), lambda_sin)
hijos_con <- rpois(length(lambda_con), lambda_con)

# Crear data frame unificado
df_predictiva <- bind_rows(
  tibble(hijos = hijos_sin, grupo = "Sin título universitario"),
  tibble(hijos = hijos_con, grupo = "Con título universitario")
)

# Graficar las distribuciones predictivas
ggplot(df_predictiva, aes(x = hijos, fill = grupo)) +
  geom_histogram(position = "dodge", alpha = 0.8, bins = 10) +
  labs(
    title = "Distribuciones predictivas posteriores del número de hijos",
    x = "Número de hijos",
    y = "Frecuencia",
    fill = "Grupo"
  ) +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    plot.title = element_text(face = "bold", hjust = 0.5), # hjust centra el texto sobre el gráfico
    plot.subtitle = element_text(hjust = 0.5) 
  )
```
:::

## Inferencia sobre la distribución predictiva posterior

En base a las distribuciones predictivas posteriores, obtén las respuetas a continuación.

### Pregunta 13

-   ¿Cuáles son las probabilidades de que una mujer (de 40 años en los 90 en USA) con 4 hijos o más sea o no titulada universitaria? ¿Cuál es la "odds" de que no sea titulada universitaria?

::: {#respuesta-13 .callout-note}

#Nota importante: se asume que la proporción muestral es la poblacional.
```{r}
# Crear data frame combinado con grupo y si tiene ≥4 hijos (argumento lógico T/F)
df_combinado <- bind_rows(
  tibble(hijos = hijos_sin, grupo = "Sin título universitario", tiene_4_o_mas_hijos = hijos_sin >= 4),
  tibble(hijos = hijos_con, grupo = "Con título universitario", tiene_4_o_mas_hijos = hijos_con >= 4)
)

# Filtrar solo simulaciones con 4 o más hijos (los T)
df_4_hijos <- df_combinado %>%
  filter(tiene_4_o_mas_hijos)

# Conteo por grupo
conteos <- df_4_hijos %>%
  count(grupo, name = "n")

# Probabilidades condicionales
total <- sum(conteos$n)
prob_sin <- conteos %>% filter(grupo == "Sin título universitario") %>% pull(n) / total
prob_con <- conteos %>% filter(grupo == "Con título universitario") %>% pull(n) / total
odds <- prob_sin / prob_con 

# Las odds en el otro sentido son 1/odds
odds2<-1/odds

# Resultados
resultados13 <- tibble(
  Grupo = c("Sin título universitario", "Con título universitario"),
  n = conteos$n,
  Probabilidad = round(c(prob_sin, prob_con), 3),
  `Odds a favor de categoría` = round(c(odds, odds2), 3)
)
resultados13

```
:::

### Pregunta 14

-   Si tomamos dos mujeres al azar, una con y otra sin titulación universitaria, ¿cuál es la probabilidad de que la mujer con titulación universitaria tenga más hijos que la mujer sin titulación universitaria?

::: {#respuesta-14 .callout-note}
```{r}
# Simulaciones ya hechas: hijos_sin e hijos_con con 1e6 simulaciones


# Comparar viendo la media de veces una mujer con titulación tiene más hijos que una mujer sin titulación
probabilidad_mas_hijos_titulada <- mean(hijos_con > hijos_sin)
probabilidad_mas_hijos_titulada

```
:::

### Pregunta 15

-   A partir de estas aproximaciones a las distribuciones predictivas posteriores, ¿podrías obtener la probabilidad conjunta de que una mujer no tenga ningún hijo y sea o no titulada universitaria? Justifica tu respuesta.

::: {#respuesta-15 .callout-note}
#Salvo que se vuelva a asumir que la proporción muestral es la poblacional, no se podría hacer sin modelar una incertidumbre en torno al parámetro, lo cual implicaría volver a generar una posterior para el parámetro dentro de la categoría "sin título". El siguiente script resuelve la cuestión asumiendo representatividad perfecta como ya se hizo en el ejercicio 13.

```{r}
#Probabilidad de tener o no estudios
p_con_estudios <- fert_estadisticos |> 
  filter(titulo_uni == "con") |> 
  pull(n) / sum(fert_estadisticos$n)

p_sin_estudios <- 1 - p_con_estudios

# Probabilidad de tener 0 hijos para cada valor simulado de lambda (para ambos grupos)
prob_0_hijos_sin <- exp(-lambda_sin)  # P(X = 0 | lambda_sin)
prob_0_hijos_con <- exp(-lambda_con)  # P(X = 0 | lambda_con)

# Promedio de estas probabilidades para obtener la probabilidad de 0 hijos por grupo
prob_0_hijos_sin_total <- mean(prob_0_hijos_sin)
prob_0_hijos_con_total <- mean(prob_0_hijos_con)


# Probabilidades conjuntas
prob_conjunta_con <- prob_0_hijos_con_total * p_con_estudios
prob_conjunta_sin <- prob_0_hijos_sin_total * p_sin_estudios

#Resultados
resultados15 <- tibble(
  Grupo = c("Sin título universitario", "Con título universitario"),
  "Probabilidad 0 hijos" = c(prob_conjunta_sin, prob_conjunta_con)
)
resultados15

```
:::

## Comprobaciones predictivas posteriores

### Pregunta 16

-   Representa la *proporción* de mujeres tituladas universitarias en función del número de hijos, junto con su distribución predictiva posterior.

::: {#respuesta-16 .callout-note}
```{r}

# Calculamos las proporciones empíricas
datos_empiricos <- fertilidad_gss_1990 |>
  filter(titulo_uni == "con") |>
  mutate(proporcion = frecuencia / sum(frecuencia)) |>
  select(n_hijos, proporcion) |>
  mutate(fuente = "Empírico")

# Y las predichas por el modelo
datos_predictivos <- tibble(n_hijos = hijos_con) |>
  count(n_hijos) |>
  mutate(proporcion = n / sum(n)) |>
  select(n_hijos, proporcion) |>
  mutate(fuente = "Predictivo")

# Unión en un df
datos_combinados <- bind_rows(datos_empiricos, datos_predictivos)

# Gráfico de barras para las proporciones empíricas y  predictivas
ggplot(datos_combinados, aes(x = n_hijos, y = proporcion, fill = fuente)) +
    geom_bar(stat = "identity", position = "dodge", width = 0.7, alpha = 0.6) +
    labs(
    title = "Proporciones Empíricas y Predictivas\npor Número de Hijos (Mujeres con Título Universitario)",
    x = "Número de hijos",
    y = "Proporción"
  ) +
  scale_fill_manual(values = c(
    "Empírico" = PALETA[2],
    "Predictivo" = PALETA[1]
  )) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.title = element_blank()
  )

```
:::

## Comprobaciones predictivas posteriores sobre la muestra

```{r n-muestra-con}
# Se extrae aquí un valor para utilizar más adelante
n_con <- fert_estadisticos |> filter(titulo_uni == "con") |> pull(n)
```

Para hacer comprobaciones predictivas, no basta con aproximar una muestra predictiva posterior.
Como has podido ver en la lectura, necesitamos obtener estimadores de dicha distribución con los que poder comparar estadísticos de la distribución muestra.

Para ello, en lugar de aproximar la distribución predictiva posterior mediante muestras de Monte Carlo, lo que necesitamos es obtener la distribución predictiva posterior del estadístico de con el que queremos comparar la muestra empírica.
Es decir, necesitamos generar "muestras empíricas simuladas", calcular ese mismo estadístico, y compararlo con el estadístico de la muestra empírica.

A continuación vamos a hacer eso mismo con las distribuciones predictivas posteriores de los dos grupos de la población estudiada

### Pregunta 17

-   Observa el máximo número de hijos que se obtiene en la distribución empírica y en la distribución predictiva posterior en la pregunta 16. ¿Cuánto es en cada caso?

::: {#respuesta-17 .callout-note}
```{r}
# Obtener los máximos empíricos para ambos grupos
max_hijos_empirico_con <- max(fertilidad_gss_1990 %>%
                                filter(titulo_uni == "con", frecuencia > 0) %>% 
                                pull(n_hijos)) #frecuencia > 0 filtra los casos que efectivamente ocurren en los datos, quitando las categorías "0" (que se completaron en el df antes)

max_hijos_empirico_sin <- max(fertilidad_gss_1990 %>%
                                filter(titulo_uni == "sin", frecuencia > 0) %>%
                                pull(n_hijos))

# Máximo número de hijos en las distribuciones predictivas posteriores
max_hijos_predictiva_sin <- max(hijos_sin)
max_hijos_predictiva_con <- max(hijos_con)

# Resultados
resultados17 <- tibble(
  Grupo = c("Sin título", "Con título"),
  Empírico = c(max_hijos_empirico_sin, max_hijos_empirico_con),
  Simulado = c(max_hijos_predictiva_sin, max_hijos_predictiva_con)
)
resultados17

```
:::

### Pregunta 18

-   Escribe una función que, dado un valor de la tasa de fertilidad $\lambda$ y un tamaño muestral $n$, simule **muestras de tamaño** $n$ de una distribución de Poisson y devuelva **un único número que sea el valor máximo** de dicha distribución. Ayúdate del prototipo de función que hay dentro del "callout".

::: {#respuesta-18 .callout-note}
```{r max-poisson}
max_poisson <- function(lambda, n) {
  
# Simular una muestra de tamaño n a partir de una distribución de Poisson
  muestra_poisson <- rpois(n, lambda)
  
  # Devolver el valor máximo de la muestra
  return(max(muestra_poisson))
}
```
:::

### Pregunta 19

-   Utilizando la aproximación a la distribución posterior de la pregunta 11 y la función `max_poisson()` que has escrito, determina el valor-$p$ predictivo posterior de obtener, según el modelo ajustado, una muestra de mujeres universitarias de tamaño `{r} n_con` en la que el máximo número de hijos sea igual o menor que el máximo empírico obtenido en la pregunta 17, e interpreta el resultado.

*(NOTA: ¡Cuidado! Probablemente tengas que "iterar" sobre las muestras de la distribución posterior)*

::: {#respuesta-19 .callout-note}
```{r}
# Se parte de la distribución posterior, de la que ya se han calculado lambda_con, n_con y max_hijos_empirico_con

# Se simulan los máximos con la función sapply, que permite aplicar una función a cada elemento de un vector (lambada_con), devolviendo directamente un vector con los resultados
max_sim <- sapply(lambda_con, function(lambda) max_poisson(lambda, n_con))

# Calcular el valor-p predictivo posterior
p_valor_predictivo <- mean(max_sim <= max_hijos_empirico_con)

# Crear un tibble con los resultados
resultados19 <- tibble(
  "P valor predictivo" = p_valor_predictivo
)
resultados19

```

#El valor p predictivo muestra que P(X\<=max_hijos_empirico_con)=0,436.
Un valor cercano a 0,5 indica una discrepancia mínima entre lo simulado y lo observado.
:::

### Pregunta 20

-   En base a tus observaciones de las distribuciones predictivas posteriores, propón una comprobación predictiva posterior en alguna (o ambas) de las distribuciones en función de la titulación universitaria. Determina el valor-$p$ predictivo posterior correspondiente e interprétalo.

::: {#respuesta-20 .callout-note}
#El siguiente código trata de falsear la siguiente afirmación: "El modelo subestima el número de mujeres con título universitario que tienen 2 hijos, como se observa en el gráfico de la pregunta 16.

#El p-valor elegido es, pues, unilateral

```{r}

# Se parte de la distribución posterior, de la que ya se han calculado lambda_con y n_con; falta la frecuencia de 2 hijos por simulación

simulados_2_hijos <- sapply(lambda_con, function(lambda) {
  sum(rpois(n_con, lambda) == 2)
})

#Se calcula la frecuencia observada para 2 hijos:
observado_2_hijos <- fertilidad_gss_1990 %>%
  filter(titulo_uni == "con", n_hijos == 2) %>%
  pull(frecuencia)

# Calcular el valor-p predictivo posterior (unilateral, para detectar subestimación)
p_valor_2_hijos <- mean(simulados_2_hijos <= observado_2_hijos)

# Crear un tibble con los resultados
resultados20 <- tibble(
  "P valor predictivo" = round(p_valor_2_hijos, 3)
)
resultados20

```

#El valor p predictivo indica que un 80,9 % de las simulaciones subestiman el número de mujeres con 2 hijos. Aunque es un valor moderado, no parece tan extremo como para ser alarmante, por lo que no se asumen discrepancias severas.
:::
